#' The purpose of this script is to fit a (quasi)binomial model to 
#' the observed frequencies of mutations that are previously determined
#' to be characteristic of a specific lineage of SARS-CoV-2.  It is meant 
#' to be run on a set of CSV outputs generated by minimap2.py

# parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 3) {
  stop("\n\nUsage: Rscript estfreq.R [input dir] [lineage CSV] ",
       "[output JSON] (metadata)\n",
       "  input dir:  run folder of CSV files generated by minimap2.py\n",
       "  constellation JSON:  path to JSON with constellation\n",
       "  output JSON:  path to write JSON of frequency estimates\n",
       "  metadata:  optional, path to metadata CSV file\n\n")
}
run.dir <- args[1]  # location of CSV outputs from minimap2.py
stelfile <- args[2]
outfile <- args[3]
metafile <- NA
if (length(args) > 3) {
  metafile <- args[4]
}


#' re.findall
#'
#' Emulate behaviour of Python's re.findall() function
#'
#' @param pat:  regex pattern
#' @param s:  character, a single string
#' @return character, vector of all matching substrings
re.findall <- function(pat, s) {
  if (!is.character(s)) {
    stop("re.findall() requires a character object for input 's'")
  }
  matches <- gregexpr(pat, s)
  index <- as.integer(matches[[1]])
  match.length <- attr(matches[[1]], 'match.length')
  
  sapply(1:length(index), function(i) {
    start <- index[i]
    stop <- start + match.length[i] - 1
    substr(s, start, stop)
  })
}

# coordinates of reading frames in reference
orfs <- list(
  'orf1a'= c(265, 13468),
  'orf1b'= c(13467, 21555),
  'S'= c(21562, 25384),
  'orf3a'= c(25392, 26220),
  'E'= c(26244, 26472),
  'M'= c(26522, 27191),
  'orf6'= c(27201, 27387),
  'orf7a'= c(27393, 27759),
  'orf7b'= c(27755, 27887),
  'orf8'= c(27893, 28259),
  'N'= c(28273, 29533),
  'orf10'= c(29557, 29674),
  'nsp2' = c(806, 2719),
  'nsp3' = c(2720, 8554),
  'nsp4' = c(8555, 10054),
  'nsp5' = c(10055, 10972),
  'nsp6' = c(10973, 11842),
  'nsp12' = c(13442, 16236),
  'nsp13' = c(16237, 18039),
  'nsp15' = c(19621, 20658)
)


require(lubridate)
require(jsonlite)
require(seqinr)


# load the lineage definition (mutation list)
lineage <- gsub("^c|\\.json$", "", basename(stelfile))

if (lineage[1] == "BA.2") {
  lineage[1] <- "BA.2/BA.4/BA.5"
}

constellation <- jsonlite::read_json(stelfile, simplifyVector = TRUE)
constellation$sites <- unique(constellation$sites)

map_sites <- list()
for (i in 1:length(constellation$sites$nt)) {
  toks <- lapply(strsplit(constellation$sites$nt[[i]], ",")[[1]], toupper)
  for(tok in toks) {
    map_sites[tok] <- constellation$sites$aa[[i]] 
  }
}

sites <- names(map_sites)

# locate data files
require(here)
mfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.mapped\\.csv$")
mfiles <- mfiles[!grepl("Undetermined", basename(mfiles))]
cfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.coverage\\.csv$")  
cfiles <- cfiles[!grepl("Undetermined", basename(cfiles))]

if(length(mfiles) == 0) 
  stop("No *.mapped.csv files found!")
if(length(cfiles) == 0) 
  stop("No *.coverage.csv files found!")
if(length(mfiles) != length(cfiles)) 
  stop("Mismatch between number of *.mapped.csv and *.coverage.csv files")


# import mutation frequency data
maps <- lapply(mfiles, function(f) {
  pos <- rep(NA, length(sites))
  names(pos) <- sites
  
  mapped <- read.csv(f, stringsAsFactors = FALSE)
  mapped$type <- substr(mapped$label, 1, 1)
  mapped$pos <- mapped$position+1
  mapped$alt <- sapply(strsplit(mapped$label, as.character(mapped$pos)), 
                       function(x) {
                         gsub("^\\.", "", x[2])
                       })
  
  mapped$label <- gsub("^~", "", mapped$label)
  sites_match <- gsub("^[^+-]", "", sites)
  index_label <- match(sites_match, mapped$label)
  
  for (i in 1:length(index_label)) {
    if (!is.na(index_label[[i]]) && is.na(pos[[i]])) {
      pos[i] <- mapped$pos[index_label[i]]
    }
  }
  list(counts=mapped$frequency[index_label], 
       coverage=mapped$coverage[index_label],
       pos=pos)
})

counts <- as.data.frame(sapply(maps, function(x) x$counts))
row.names(counts) <- sites

sample.id <- sapply(strsplit(mfiles, split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})
names(counts) <- sample.id

cvr <- as.data.frame(sapply(maps, function(x) x$coverage))
row.names(cvr) <- sites
names(cvr) <- sample.id

# determine nucleotide position of constellation mutations 
positions <- as.data.frame(sapply(maps, function(x) x$pos))
if (all(is.na(positions))) {
  pos <- rep(NA, length(sites))
} else {
  pos <- as.integer(apply(positions, 1, function(r) {
    tab <- table(r)
    as.integer(names(tab)[which.max(tab)])
  }))  
}


# handle missing positions (mutation never observed)
for (i in which(is.na(pos))) {
  # guess from mutation annotation

  # parse position directly
  num <- re.findall("\\d+", sites[i])
  pos[i] <- as.integer(num)

}


# import coverage data to supplement missing coverage
cvr2 <- sapply(cfiles, function(f) {
  coverage <- read.csv(f, stringsAsFactors = FALSE)
  # NOTE: coverage$position is 0-index, pos is 1-index
  idx <- match(pos, coverage$position+1)
  coverage$coverage[idx]
})
cvr2 <- as.data.frame(cvr2)
row.names(cvr2) <- sites
names(cvr2) <- sample.id


if (any(dim(cvr) != dim(cvr2))) stop("Mismatch in coverage matrices")
for (i in 1:nrow(cvr)) {
  for (j in 1:ncol(cvr)) {
    if (is.na(cvr[i,j])) {
      # fill in missing values from coverage files
      cvr[i,j] <- cvr2[i,j]
    }
    if (cvr[i,j] > 0 & is.na(counts[i,j])) {
      # set missing counts to zero if coverage exists
      counts[i,j] <- 0
    }
  }
}

# convert to integer counts and transpose so mutations are columns
counts <- as.data.frame(t(counts*cvr))
cvr <- as.data.frame(t(cvr))


# parse metadata, dealing with varying header labels and date formats
metadata <- data.frame(sample=sample.id)
metadata$lab <- sapply(cfiles, function(x) {
  tokens <- strsplit(x, "/")[[1]]
  tokens[length(tokens)-2]
})
metadata$coldate <- rep(NA, times=nrow(counts))
metadata$site <- rep(NA, times=nrow(counts))

if (!is.na(metafile)) {
  meta <- read.csv(metafile)
  #idx <- match(counts$sample, meta[,which(grepl("sample\\.ID", names(meta)))])
  r1.fn <- meta[,which(grepl("[Rr]1\\.fastq\\.filename", names(meta)))]
  idx <- match(metadata$sample, sapply(r1.fn, function(x) {
    strsplit(as.character(x), "_")[[1]][1]
  }))
  
  # parse sample collection dates
  date.col <- which(grepl("collection\\.date", names(meta)))
  if (is.na(date.col)) {
    warning("Failed to locate sample collection date column.")
  } else {
    date.str <- meta[idx, date.col]
    metadata$coldate <- as.Date(parse_date_time(date.str, c("mdy", "dmy", "ymd")))
  }
  
  # parse sampling location
  loc.col <- which(grepl("location.name", names(meta)))
  if (is.na(loc.col)) {
    warning("Failed to locate sampling location in metadata")
  } else {
    metadata$site <- meta[idx, loc.col]
  }
}


# sort by site and collection date
idx <- order(metadata$site, metadata$coldate, metadata$sample, decreasing=T)
metadata <- metadata[idx, ]
counts <- counts[idx, ]
cvr <- cvr[idx, ]

# issue 55 - set count to NA if coverage is less than 10
lo_cvr_filter <- sapply(cvr, function(x) ifelse(x < 10, NA, 1))
counts <- counts * lo_cvr_filter


# estimate variant frequencies
probs <- rep(NA, nrow(counts))
lo <- rep(NA, nrow(counts))
hi <- rep(NA, nrow(counts))
for (i in 1:nrow(counts)) {
  y <- as.integer(counts[i, 1:ncol(cvr)])  # number of "successes"
  n <- as.integer(cvr[i, ])  # number of trials
  if(sum(!is.na(y)) == 0) {
    next  # should try to fit a model to at least one data point
  }
  probs[i] <- tryCatch({
    fit <- glm(cbind(y, n-y) ~ 1, family='quasibinomial')
    exp(fit$coef) / (1+exp(fit$coef))  # probability
    }, 
    error = function(cond) { return (NA) }
    )
  if (sum(is.na(y)) < length(y)-1 & 
      !is.na(probs[i]) & 
      (probs[i] >= 1e-5 & probs[i] <= 1-(1e-5)) ) {
    suppressMessages(ci <- tryCatch(confint(fit)))
    lo[i] <- exp(ci[1]) / (1+exp(ci[1]))
    hi[i] <- exp(ci[2]) / (1+exp(ci[2]))
  }
  
  # handle edge case where coef > 100
  if (is.nan(probs[i])) {
    boots <- sapply(1:1000, function(i) {
      idx <- sample(1:length(y), length(y), replace=T)
      attempt <- 0
      while (all(is.na(y[idx]))) {
        idx <- sample(1:length(y), length(y), replace=T)
        attempt <- attempt + 1
        if (attempt == 10) {
          stop("Attempted to sample indexes from 'y' with at least one ",
               "non-NA value too many times")
        }
      }
      fit1 <- glm(cbind(y[idx], n[idx]-y[idx]) ~ 1, family='quasibinomial')
      bp <- fit1$coefficients[1]
      ifelse(bp > 100, 1, exp(bp)/(1+exp(bp)))
    })
    probs[i] <- mean(boots, na.rm=T)
    lo[i] <- quantile(boots, 0.025)
    hi[i] <- quantile(boots, 0.975)
  }
}
estimate <- data.frame(est=probs, lower.95=lo, upper.95=hi)
row.names(estimate) <- row.names(counts)

output_samples <- rep(NA, length(sample.id) * length(sites))
output_mutations <- rep(NA, length(sample.id) * length(sites))
output_nucleotides <- rep(NA, length(sample.id) * length(sites))
output_counts <- rep(NA, length(sample.id) * length(sites))
output_cvr <- rep(NA, length(sample.id) * length(sites))

i <- 0
for (sample in row.names(counts)) {
  for (site in sites) {
    i <- i+1
    output_samples[i] <- sample
    output_mutations[i] <- map_sites[site][[1]]
    output_nucleotides[i] <- site
    output_counts[i] <- counts[sample,site]
    output_cvr[i] <- cvr[sample,site]
  }
}

sample_information <- data.frame(sample=output_samples, mutation=output_mutations, 
                                 nucleotide=output_nucleotides, count=output_counts,
                                 coverage=output_cvr)

# write output JSON
output <- list(results=sample_information, metadata=metadata,
               estimate=estimate, lineage=lineage, run.dir=run.dir)
jsonlite::write_json(output, outfile, pretty=TRUE)

